{
  "calibrationMessages": {
    "calibrateFirst": {
      "summary": "Only ${int8Share} of layers in your model are executed in the 8-bit integer precision.",
      "nextSteps": "[Perform INT8 calibration](/projects/edit-calibration/${projectId}) to have layers executed in the 8-bit integer precision. \n\nRecommended workflow: \n\t1. Calibrate a model with the Default method. \n\t2. Measure the performance of the calibrated model. \n\t3. Evaluate the accuracy of the calibrated model. \n\t4. If accuracy loss after calibration with the Default method is too big, calibrate the original model with the AccuracyAware method. With this method, you can specify maximum tolerable accuracy drop. However, a model calibrated with the AccuracyAware method potentially has less layers in the I8 precision that results in performance loss if compared to the model calibrated with the Default method.",
      "theory": "[INT8 calibration](https://docs.openvino.ai/latest/workbench_docs_Workbench_DG_Int_8_Quantization.html) accelerates performance on hardware that supports INT8 by transiting layers to integer calculations. \nThe Default method provides maximum possible calibrated models. You cannot increase the ratio of layers executed in the 8-bit integer precision after calibration with Default. AccuracyAware only helps to decrease accuracy drop by reducing the ratio of 8-bit integer layers, which leads to a slight performance loss."
    },
    "unquantizedConvolutions": {
      "summary": "${fpConvShare} of convolution layers in your INT8 calibrated model are executed in a floating-point precision",
      "nextSteps": "[Perform INT8 calibration](/projects/edit-calibration/${projectId}) to speed up your model. \n\nRecommended workflow: \n\t1. Calibrate a model with the Default method. \n\t2. Measure the performance of the calibrated model. Performance that you get using the Default method is the maximum available performance for this model on the selected device. \n\t3. Evaluate the accuracy of the calibrated model. \n\t4. If the accuracy number is not great enough for your problem, calibrate the original model with the AccuracyAware method. With this method, you can specify maximum tolerable accuracy drop. However, a model calibrated with AccuracyAware never outperforms the same model calibrated with Default.",
      "theory": "[INT8 calibration](https://docs.openvino.ai/latest/workbench_docs_Workbench_DG_Int_8_Quantization.html) accelerates performance on hardware that supports INT8 by reducing the number of layers in a floating-point precision. \nWhen using the Post-training Optimization Tool that is available inside the DL Workbench, you are guaranteed to have all convolutional layers executed in the INT8 precision. \nThe Default method ensures the maximum possible performance for a particular model, therefore reapplying the method to the same model leads to the same result."
    }
  },
  "generalRules": {
    "goToFP16": {
      "summary": "Only ${fp16Share} of layers in your model executed on a GPU device are in the FP16 precision.",
      "nextSteps": "[Import the model again](/model-manager/import) and choose FP16 precision in the conversion form",
      "theory": "FP16 precision provides models that take up less memory footprint and speed up throughput on a GPU."
    },
    "reordersOverload": {
      "summary": "Reorder layers take ${reordersShare} of the model execution time.",
      "nextSteps": "Identify whether this happens due to layout changes or precision changes. \na. If Reorder layers are layout-related and take more than 10% of the execution time, consider applying [OpenVINO extensions](https://github.com/openvinotoolkit/training_extensions) on the layers that follow Reorder layers to support new layouts. This should remove most of such Reorder layers. Note that the DL Workbench does not support extensions to the runtime, so continue with the command-line OpenVINO functionality. \nb. If Reorder layers are precision-related and take more than 10% of the execution time, analyze the precision transitions and change the model so that it has a more homogenous precision. For example, [perform INT8 calibration](/projects/edit-calibration/${projectId}) or [import the model again](/model-manager/import) and choose the FP16 precision in the conversion form. This should remove most of such Reorder layers.",
      "theory": "Reorder layers are inserted automatically due to layout changes to improve performance or due to precision changes. A common practice is to insert Reorder layers at the beginning or at the end of a topology. Examine the layer that comes before a Reorder layer and the one that comes after the Reorder layer. Compare the layout and precision of these layers. If the precision is different, the Reorder layer is most likely precision-related. If the precision does not differ, the layer is performance related."
    },
    "reordersOverloadInt8": {
      "summary": "Reorder layers take ${reordersShare} of the model execution time.",
      "nextSteps": "Identify whether this happens due to layout changes or precision changes. \na. If Reorder layers are layout-related and take more than 10% of the execution time, consider applying [OpenVINO extensions](https://github.com/openvinotoolkit/training_extensions) on the layers that follow Reorder layers to support new layouts. This should remove most of such Reorder layers. Note that the DL Workbench does not support extensions to the runtime, so continue with the command-line OpenVINO functionality. \nb. If Reorder layers are precision-related and take more than 10% of the execution time, analyze the precision transitions and change the model so that it has a more homogenous precision. For example, perform INT8 calibration or [import the model again](/model-manager/import) and choose the FP16 precision in the conversion form. This should remove most of such Reorder layers.",
      "theory": "Reorder layers are inserted automatically due to layout changes to improve performance or due to precision changes. A common practice is to insert Reorder layers at the beginning or at the end of a topology. Examine the layer that comes before a Reorder layer and the one that comes after the Reorder layer. Compare the layout and precision of these layers. If the precision is different, the Reorder layer is most likely precision-related. If the precision does not differ, the layer is performance related."
    }
  }
}
