{% include 'autogenerated_note_code.jinja' %}

import csv
from collections import defaultdict
from pathlib import Path
from pprint import pprint


# number of samples to prepare for benchmark
samples_to_prepare = streams * batch
binary_dataset_path = Path("binary_dataset")
binary_dataset_path.mkdir(exist_ok=True)

input_files_mapping = defaultdict(list)

def save_binary_sample(sample, dataset_dir, data_types, idx=0):
    for (input_name, input_data), data_type in zip(tokenized_sample.items(), data_types):
        file_name = binary_dataset_path / f"{input_name}_{idx:03d}.bin"
        with open(file_name, 'w') as file:
            input_data.astype(data_type).tofile(file)

        input_files_mapping[input_name].append(str(file_name))

with open(dataset_path) as file:
    dataset_reader = csv.reader(file)
    for idx, row in zip(range(samples_to_prepare), dataset_reader):
        input_sample = row[:-1]  # without label
        tokenized_sample = tokenizer(input_sample, **tokenizer_kwargs)
        save_binary_sample(tokenized_sample, binary_dataset_path, data_types, idx)

print("Binary files for Benchmark App:")
pprint(dict(input_files_mapping))

# convert to string for benchmark app
input_files_mapping = ",".join(
    f"{input_name}:" + ",".join(files) for input_name, files in input_files_mapping.items()
)
print(f"Benchmark App input:\n-i {input_files_mapping}")